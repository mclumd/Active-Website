
Reasoning in a complex and dynamic world requires considerable
flexibility on the part of the reasoner; flexibility to apply -- in
the right circumstances -- the right tools (eg probabilities,
defaults, metareasoning, belief revision, contradiction-resolution,
and so on).  A formalism that has been developed with this purpose in
mind is that of active logic.  An active logic is one that combines
inference rules with a constantly evolving measure of time (a `now')
that itself can be referenced in those rules. As an example, from
Now(5) [the time is now 5] one infers Now(6) since the fact that an
inference has taken place implies that time (at least one `time-step')
has passed.

From this feature come others, most notably:

a. ignorance-assessment amounts to a lookup at time t, of what was
    known prior to t.

b. contradictory information can (sometimes) be detected and used to
   curtail nonsensical inferences as well as to initiate repairs.

c. default conclusions can be characterized in terms of lookups to see
   whether one has information (directly) contrary to the default.

d. reasoning can be kept current, ie, inferences can be triggered to
   occur when they should, and this itself is done declaratively so
   that it is also under control of (easily modifiable) inferences.

These features of active logic provide mechanisms to deal with
various forms of uncertainties arising in computation. 
%One form of
%uncertainty that arises in computation is in the 
%information that a computing agent has at any instant of time. This
%type of uncertainty arises because of various reasons, including the
%following: 

A computational process P can be said to be {\em uncertain} about a
proposition (or datum) X if it explicitly represents X as (i) in the
knowledge base (KB) but possibly a mistake, or (ii) in the KB and
initially correct but possibly no longer correct; and also (iii) if it
represents X (and -X) as not present in the KB and also as items it
cannot compute or infer.  (This latter case is often undecidable in its
fullest form; active logic provides a convenient shortcut that we will
return to below.)


%1. data that is incorrect from the outset.

%2. data that becomes incorrect as the world changes.

%3. missing data (either never in the KB at all, or lost)

%If data is called into question, and
%before the subsequent assessment is made, it is (in that intermediate
%time) uncertain whether the data is (apparently) correct or not; or,
%alternatively, whether it is available (present in the KB) or not.


Two of the major computational approaches for representing and using
uncertainty are via (a)
explicit confidence levels of the data as in probability (eg, Bayesian
Networks), and (b) non-monotonic approaches as in Default Reasoning.

footnote:
Probabilistic approaches, while having much to commend them (eg, they can
be very efficient in many cases), ...



Uncertainties of type (i)  above lend themselves to
representation by approach (a); and somewhat less so for type (ii);
and even less for type (iii).  On the other hand, a suitably configured
default reasoner can represent all of these, and without special
{\em ad hoc} tools; that is, active logic already has, in its
time-sensitive inference architecture, the means for performing
default reasoning in an appropriately expressive manner. It is the
purpose of this paper to elaborate on that claim; the format consists
of an initial primer on uncertainty in active logic, then its current
implementation (Alma/Carne), existing applications, and finally a
discussion of potential future applications.


%In (i), there may be no facility that assesses outright whether the
%data is correct, but rather provides a measure of confidence one has
%in the data.  Since, this measure of confidence cannot be accurately
%determined, there will be uncertainty in the confidence measure itself. 

\section{Primer on Active Logic and Uncertainty}


Current versions of active logic do not explicitly represent
confidence levels of 
the KB (although it certainly can be made to do so). Instead, it has
the flexibility to distrust any of its beliefs in the presence of
suitable counter evidence. In effect, active logic treats its current
beliefs as simply true
until such time as reasons arise for doubting them, and then
distrusts them until such time as they may be reinstated. Degrees of
likelihood are not currently used (although the formal details
do not prevent that). One can thus regard (the current version of)
active logic as a kind of time-sensitive nonmonotonic reasoning engine.

Two of the principle mechanisms that provide the flexibility of
active logic, especially in regard to uncertainty, are {\em
contradiction-detection}  and {\em introspection}.

{\bf Contradiction-detection:} If $P$ and $\neg P$ are both
in the KB at any step, then both 
become distrusted in the next step and a repair process is initiated
(which may or may not be conclusive). Such a distrust and repair
process can occur in cases (1) and (2). For instance, if $P$ is believed
originally, but later $\neg P$ is either derived or observed (due to, $P$
being false always, $P$ becoming false or even error), then a conflict
occurs between $P$ and $\neg P$. This would cause active logic to enter a
state of ``uncertainty'' wrt $P$ and $\neg P$ leading to distrust both P and
$\neg P$ and to initiate a repair process to
adjudicate between the `old' $P$ and `new' $\neg P$. (Unlike most
belief-revision formailisms, AL does not automatically assume that the
newest data is more accurate). 

%For instance, if $P$ is both believed and true initially, but later it
%becomes false, observations will lead to the belief $\neg P$ which would
%conflict with $P$. Or, if $P$ is believed but $\neg P$ is derived a
%few steps latercan both appear in
%the KB together

An example will help:  Suppose that the KB contains the item
"Yellow(tweety)".  This might be taken (and used) simply at face value,
even if it may (unknown to the reasoner) be incorrect, until such time
as counterevidence appears (eg a photo showing a green Tweety). At
that time, assessment may lead to rejection of the initial belief; or it
may lead to its reinstatement, and rejection of the photo data (for
instance if it is also learned that the photo was developed poorly, or
taken in green light).  (This instead of assuming confidences for various
of the data items and combining them into a revised confidence measure
for Yellow(tweety).)

{\bf Introspection:} Another mechanism that provides the flexibility
of active logic is its ability to note that it does not have a given
belief $P$, represented as $\neg Know(P)$ and $\neg Know (\neg P)
$. This ability can be applied to encode uncertainties in
uncertainties of type (iii) above.  Here it is crucial that $Know$ is
interpreted as ``currently-in-the-KB'', and not as (an often undecidable)
``impossible-to-compute.''  Thus an intractable or even uncomputable
problem is replaced with a simple lookup in the (always finite) KB. In
the above yellow bird example, this can be used as part of a default,
to wit: ``if something looks yellow and if I (currently) have no
knowledge that there is an irregularity about the situation, then I
will conclude that it in fact is yellow.''\footnote
{
This formulation comes close, at least intuitively speaking, to
McCarthy's notion of circumscription with an abnormality predicate;
see \cite{mccarthy...}
}
And then, if the conclusion that Tweety is yellow is found to be
problematic (in the form of conflicting with other data) that
conclusion can be retracted (or precisely, disinherited at
subsequent timesteps, since the actual inferential history is
preserved).


% In 2 and 3, there may be facilities leading to an assessment whether
% or not the data of interest is (apparently) correct; and in 4, whether
% or not the data is available.  
% Yet all of these can be regarded as situations of uncertainty. In 2-4 this
% is so in various respects. 
%We lump 2-4 together because there is an existing tool (active logic
%-- AL -- and its implementation -- ALMA) that allows for reasoning in
%these cases.  
