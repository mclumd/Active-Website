
\subsection{Time Sensitive Automated Theorem Prover}
Can an automated theorem prover function -- to its advantage -- more
like a (human) mathematician?  One way in which this might be possible
is via time-sensitivity.  A human is highly aware of the passage of
time, and in particular to time well-spent as opposed to ill-spent. 

Thus a mathematician might, after months (or hours, or even minutes)
of pursuing a particular line of investigation, decide that it is not
paying off, and instead try a different track.  Active logic, with its
built-in time-sensitivity, provides a potential mechanism for
exploring this possibility. The obvious advantage is that, although a
computer may not care that it runs a given program for hundreds of
years in a search for a proof, {\em we} certainly care and we will
want it to try a different tack long before many years go by.

There is another likely possible advantage here, something inherent in
the active logic framework: it avoids the KR inflexibility of most
traditional AI systems. In creative activities such as mathematical
reasoning, often the introcuction of a key new concept, or even an
improved (and possibly inequivalent) reformulation of an old concept,
can vastly shorten the argument or even recast it entirely. But AI
systems typically are stuck in a fixed means of representing their
knowledge and cannot, for instance, use P(x) to refer to pairs of
numbers at one time, and later to prime numbers. Indeed, such systems
cannot easily give up a belief, and when they do (``belief
revision''), it is lost rather than available for further
consideration. This is not to say that active logic has a built-in
general-purpose concept-formation mechanism; but it does have the
expressive power to represent and reason with such formations, if they
were made available, perhaps along lines of AM \cite{lenat...}.

Furthermore, as seen earlier, active logic allows for recognition that
a given 
statement is already known, or that it's negation is known, or that
neither is known, thereby avoiding re-derivation of a theorem.
Similarly, if such a purported human-style-theorem-prover (HSTP) that
is allowed to run in continual mode (rather than started up at a
user's request) already working on a proof of X, it can respond, if
asked (again) whether X is true, that it is uncertain but that a proof
is already underway and that it has established such-and-such lemmas,
and so on; or that it has given up since the considerable time spent
has not resulted in results that support further effort.

% manjit + paul:


\subsection{Interactive Mathematical Companion - IMC}
We envision an AL-based interactive system, which, in conjunction with
an appropriate computational mathematical package (MP) as well as a
conventional theorem prover (TP), can act as a virtual mathematical
assistant and/or companion. 
%The setup may be as shown in the figure
%(fig.ALMA). 
It may be used in a variety of modes as illustrated by the
following scenario outline.

A client may wish to use IMC to ask a (mathematical) question. IMC can
try to understand the question on the basis of its existing KB and
quite possibly be able to answer the query. Or it may not understand
some of the terms used by the client and ask the client to explain
them.  The desired interactions such as IMC trying to clarify the
meaning of terms can be achieved easily by AL with its ability of
detecting and handling ignorance.  Thus a dialog may ensue in which
IMC may take note of the new definitions or facts relevant to the
query that the client furnishes in much the same manner as an
interested professional colleague might. After this preliminary
dialog, IMC may find that it is unable to answer the question from its
(local) KB (even though it 'thinks it understands the question'). At
this point, IMC may consult the TP to see if TP has an answer to the
client's question. If TP can respond affirmatively (within the time
specified by IMC), IMC can capture the answer, convey the same to the
client and also update its KB. In this way IMC is 'learning' from the
interaction with the client.

If TP is unable to provide the answer, uncertainty prevails for the
client as well as IMC. TP's inabilty to provide the answer may be
because one of the two reasons. Either it is not given sufficient
time, or it may just be unable to prove it from the hypotheses
contained in the query. In any case IMC can tell the client that it
does not know the answer to the question. Uncertainty persists.

The client may then try to pursue some thought of her own. She may
come to a point where it is necessary to compute something (possibly
as an intermediate step). She may choose to ask IMC to do the
computation. IMC interprets client's command and formulates the
necessary computation as a request and submits it to the MP. When (and
if) it receives the response from MP it passes it back to the client.
Such an interaction between the client and IMC can continue
indefinitely until the client decides to terminate it. IMC is thus
able to mobilize the mathematical resources for the client.

At each step, during the course of an interaction such as outlined
above, IMC checks any new facts that are submitted to it by the
client, or that are responses it gathers from MP or TP, against its
current KB. If the new facts are consistent with the KB, they are
recorded as assertions in its KB along with the (time) step number
when it was entered. If any fact is in conflict with any existing item
in the current KB, the contradiction is noted and client is made aware
of the contradictands. AL provides a convenient framework
%environmemt (methodology?)  
in which IMC can be implemented.

The ability of IMC to keep track of facts as they develop and to
detect contradictions can be put to good use by any client who might
be trying to check the truth of (or construct a proof of) a
proposition.


\subsection{Continual Computation}
A student of AI will soon find out that, almost without exception, any
interesting problem is NP-hard.  When a computer scientist is
confronted with a hard problem, there are several options to deal with it.
One is to simplify the problem, or identify a simpler subproblem so that it
can be solved algorithmically and automated, and leave the hard part for
the human.  Another option is for the scientist to study the problem
carefully, derive some heuristics, and hope that they will be adequate
most of the time.  But none of these is quite satisfying: ideally, we would
like the computer to do as much work for us as possible, and hopefully, be
able to derive the heuristics by itself.  A promising approach toward
realizing this ideal is the notion of \emph{continual computation}
\cite{horvitz1997:models_continual}.

The main motivation behind continual computation is to exploit the
\emph{idle time} of a computation system.  As exemplified by usage pattern
of desktop computers, workstations, webservers, etc of today, most computer
systems are under utilized: in typical employments of these systems,
relatively long spans of inactivity are interrupted with bursts of
computation intensive tasks, where the systems are taxed to their limits.
How can we make use of the idle time to help improve performance during
critical time?

% The potential value of principles of continual computation for leveraging
% idle resources is especially highlighted when considering the challenge of
% creating autonomous inference and planning systems that are immersed in
% real-world environments, tasked with sensing and acting over prolonged
% period of time.  Such situated systems may frequently be in a resting
% state, but can expect to eventually face events and challenges that may
% lead to real-time computational bottlenecks.

Continual computation generalizes the definition of problem to encompass
the uncertain stream of challenges faced over time.  One way to analyze
this problem is to put it into the framework of probability and utility, or
more generally, rational decision making:
\begin{quotation} Policies for guiding the precomputation and caching of
  complete or partial solutions of potential future problems are targeted
  at enhancing the expected value of future behavior.  The policies can be
  harnessed to allocate periods of time traditionally viewed as idle time
  between problems, as well as to consider the value of redirecting
  resources that might typically be allocated to solving a definite,
  current problem to the precomputation of responses to potential future
  challenges under uncertainty\cite{horvitz2001:principles}.  
\end{quotation}

An implicit assumption of the utility-based work in continual computation
is that the future is somehow predictable.  But in many cases, this cannot
be expected.  For example, for long term planning, most statistics will
probably lose their significance.  Here is a place where systems like
Lenat's AM can play a complementary role, in a similar way where
mathematics plays a complementary role to engineering principles.  Just as
mathematicians usually do not rely on immediate reward to guide their
research (yet discover theorems of utmost utility), AM can function in a
way independent of the immediate utility of its work.  

More precisely, if we adopt logic as our base for computation and look at
problem solving as theorem proving \cite{?}, a system capable of
discovering new theorems can become a very attractive model of a continual
computation system.  In such a system, every newly discovered theorem has
the potential of simplifying the proof of future theorem; so in essence,
theorem becomes our universal format for caching the result of
precomputation and partial solutions to problems.  

% However, the theorem proving based approach to continual computation
% provides challenges of its own.  In the absence of utility as guidance,
% identifying the concept of ``interestingness'' becomes the central issue in
% automated mathematical discovery.  

A simplistic embodiment of the model can just be a forward chaining system
capable of combining facts in its database to produce new theorem using
modes ponen, for instance.  Such a system is not likely to be very useful,
however, because it will spend most of its time deriving uninteresting
theorems.  So the success of this model of continual computation will hinge
on whether we can find meaningful criteria for the ``interestingness'' of a
theorem.  In the classical AM
\cite{lenat1982:am,lenat1983:theory_formation,lenat/brown1984:why_am}, the
system relies largely on human to provide the judgement of interestingness.
In a survey of several automated discovery programs,
\cite{colton/bundy1999:notion_interestingness} identify several properties
of concepts which seem to be relevant to their interestingness, such as
novelty, surprisingness, understandibility, existence of models and
possibly true conjectures about them.  Although these properties seem
plausible, it is not obvious they are precise enough to be operational to
guide a automated discovery programs toward significant results.

Mathematical concepts are characterized by their abstractness.  In fact, it
is unclear whether the interestingness property of concepts is even
meaningful at such abstract level, where the concepts are stripped to their
bare essential, sanitized from any domain specificity: in real life, our
interests seem always to be tied to our biological existence in physical
world.  When isolated from all real-world interpretations, is there an
objective way to tell one theorem is more ``interesting'' then another?
Although we don't have answer to this question, we have reason to be
optimistic: mathematics has worked so well for us.

%If this interestingness property is indeed meaningful, it will probably be
%defined in term of other highly abstract concepts, such as the length of
%its derivation.

% Exploiting domain dependent information in a domain independent way.
The so called \emph{No Free Lunch Theorem}
\cite{wolpert/macready1995:no_free,wolpert/macready1997:no_free} states
that ``all algorithms that search for an extremum of a cost function
perform exactly the same, when averaged over all possible cost functions.''
In other words, without domain specific structural assumptions of the
problem, no algorithm can be expected to perform better on average than
simple blind search.  This result appears to be a cause for pessimism for
researchers hoping to devise domain-independent methods to improve
problem solving performance.  But on the other hand, this theorem also
provides compelling reason for embracing the notion of continual
computation, which can be seen as a way to exploited domain dependent
information in a domain independent way.  We believe that a forward
chaining logic system such as active logic, with its expressivity and
reflective capability to reason about proofs and derivations, is
well-equipped to take advantage of the opportunity offered by continual
computation.
