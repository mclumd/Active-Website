<HTML>
<HEAD>
<TITLE>Computable NMR</title>
</head>

<!body bgcolor="#ffffee" text="#000000" link="#ff0000" vlink="0000ff">
<body bgcolor="#eeeeee" text="#000000" link="#ff0000" vlink="0000ff">

<h2>Computable nonmonotonic logic for commonsense reasoning  </h2>

<p>
The knowledge that we have of the domains in which we typically want
to employ a commonsense reasoner is incomplete and uncertain.
Nonmonotonic logics are one of the techniques have been developed for
reasoning in these circumstances.  Nonmonotonic logics are all
nonmonotonic: if $T \models \phi$, it is not necessary that $T \cup
T_1 \models \phi$.  However, another characteristic of nonmonotonic
logics is non-computability. In the general case, there is no
algorithm that will tell whether a formula $\phi$ follows from a
nonmonotonic theory $T$ or not.  This is a serious problem and has
restricted the practical use of nonmonotonic logics.
<p>

<h2>Approach</h2>

 The approach I take is to view nonmonotonic reasoning
as reasoning with the possibility of mistakes with clues as to how to
resolve the mistake specified in the logic as defaults and preferences
among the defaults. An aspect of that approach is that the computation
does not stop once we have derived what is desired. If we are
interested in knowing whether P, we do not stop computing once P or
not(P) is derived. Rather, since we know that this may be mistaken, we
continue computing in case we discover that the opposite is
true. Assume that P is derived first. Further computing might produce
not(P) and using the defaults and preferences the logic might conclude
that the previous derivation was mistaken and adopt not(P). With more
information or computation, the logic may change back to P.  There is
no end to this since the logic is not computable. What we have then is
a sequence of answers to the question of whether P. Each new answer,
however, is better than the previous one since it takes into account
the reasoning used in the previous answer and still prefers the new
one. This results in an anytime-like behavior for the logic--as time
goes on, our confidence in the successive answers should increase.
<p>
The idea of a constantly changing answer might not seem very
sound--how can we know what really follows from the theory? As noted
above, there is no algorithm that can answer that. The good thing
though is that while it is possible to contrive domains where the
answer switches forever, we believe that this will not be the case for
commonsense uses of the logic. The answer is likely to settle fairly
rapidly and that can be taken to be the correct answer (unless it
changes). This is to be verified empirically.
<p>
An additional feature of our approach is that it naturally
incorporates new information into the computation. We do not expect a
commonsense agent to start with all the information it needs. It is
likely to gather information as it runs and use that in its
reasoning. If the agent gathers new information that is relevant to a
question under consideration, that information can change the answer
of the logic. No additional mechanism is needed to incorporate the new
information, and we do not need to start a new proof process each time
there is new information.
<p>

<h2>Sketch of the behavior</h2> 

The language of the logic is a first order language with default
formulas and a preference relation among the defaults. The logic
derives the consequences of a default (applies the default) if its
antecedent is true unless a preferred default has been applied before
that time. It could turn out however, that the preferred default is
applied at a later time because more computation or more observations
are required to derive the antecedent of that default. In that case
the previous conclusion, together with its consequences are withdrawn
and a new, better answer is obtained. We see then that given more
time, more computation can be done which can result in a better
answer.  The new default too could be subject to the same process and
the answer may change again.
<p>
Another possibility for change in the answer is if a non-defeasible
formula is inconsistent with the conclusion of a default. The
non-defeasible formula is preferred and the default conclusions
withdrawn. A generalization of this case is when a group of defaults
is jointly inconsistent with some non-defeasible formulas. In that
case, none of the defaults involved can be justified and all are
withdrawn.
<p>
This logic has been implemented in an active logic framework. The
introspection, inconsistency tolerance and meta-reasoning capabilities
of active logic are crucial for the implementation.
<p>

<h2>Semantics</h2> 
A preferential model semantics has been used to design
this logic. WE cannot guarantee a correspondence between the state of
the KB at any time with the preferred models because of the
non-decidability of the logic. However, weaker results can be expected
showing some kind of anytimeness.
<p>

<h2>Tests</h2>
The logic has been applied to a number of examples from
the literature and it has been found to perform as expected. In some
cases though, the expected answer is not the first one that
appears-- more computation gives better answers, as expected.
<p>
<h2> Issues</h2> 

The system needs to be tested with larger commonsense
examples to test the hypothesis that the answers do not forever cycle
in these domains. The question of control of the computation has to be
addressed. There is also a need to characterize the behavior of the
logic. 



</html>