.th
.sc
.EQ
delim $$
.EN
.po -0.4i
.ll 6.8i
.ls 1
.ce 100
\fBAUTOCIRCUMSCRIPTION\fR
.sp 2
Donald Perlis
.sp
Department of Computer Science
and
Institute for Advanced Computer Studies
University of Maryland
College Park, MD 20742
.sp 2
\fBAbstract\fR
.pp
Reasoning can be used to select among various possible
interpretations of events. But how are these possibilities
determined?
We isolate two key technical features of circumscription (consistency and
minimization), and use the first as the basis for a reformulation of the
circumscription principle in a way related to possibility, self knowledge,
and negative introspection.  The second (minimization) then can be separately
expressed on its own.  Conceptual clarity and a kind of validity are results
of this separation, as well as a computational means to determine (sometimes) when a wff
is \fInot\fR among a reasoner's conclusions.
.ls 2
.sp 
\fBI. Introduction\fR
.pp
Assessing possible states of affairs with respect to given knowledge
is an essential feature of making sense of the world. This is because
our knowledge is generally very incomplete, so we
need to reason about the gaps in our knowledge. Once we
have isolated various possibilities, we may choose among
them, perhaps selecting one as a plausible conjecture
until evidence convinces us to leave it. Thus such conclusions
are defeasible, and this provides a basis for non-monotonic reasoning.
.pp
But a question that in some sense comes first, is:
How do we determine that
a wff is indeed possible, with respect to what we do know?
One idea is that to recognize a gap (ignorance) in our knowledge \fIis\fR to recognize
alternative possibilities. The absence of knowledge that, say, \(*a,
amounts to the possibility that \(no\(*a.
In effect, we are theory-builders;  we build tentative theories
about the world on the basis of what
we determine that it is consistent to postulate.
That is, if we can find a consistent interpretation of our concepts, we
may view it as a possibility: x is possible if we do not know
(cannot prove) x is false.\**
.(f
\**In [17] I discuss some further concepts of possibility in commonsense
reasoning.
.)f
Once we have
found such an interpretation, we may try to assess whether it
is worth taking seriously.
This bears on another fact, namely that consistency-testing is in
general undecidable. This is in fact why most formalisms for
non-monotonic reasoning do not have effective proof procedures.
Circumscription has the virtue of being the one fairly general
(semi)-decidable
formalism available. This will lead us to some insights into the prior
problem of determining possibilities.
.pp
In [12] McCarthy introduced the idea of circumscription, and it was soon
recognized as a powerful and important new technique in
artificial intelligence and logic. However, the foundational
and conceptual status of circumscription, in its various versions\**,
.(f
\**At my last count there were at least eight versions of circumscription on
the AI market. My apologies for introducing yet another here. I offer the
mitigating plea that \fIthis\fR one is not really circumscription at all, in
the sense that it does not aim at minimizing extensions, though it
does borrow outright the truly novel portion of McCarthy's original schema.
.)f
has remained unsettled (see
Davis [1], Etherington et al [2], Lifschitz [8,9]; McCarthy [12,13], Perlis
& Minker [22])
and also bound up with the equally unsettled status of various
theories of default reasoning. Here we focus on one of the key advances
provided by McCarthy's original insight, namely a way to finesse consistency
proofs. McCarthy exploited the intuition\**
.(f
\**That is \fIalmost\fR true (see [1,2]). Shepherdson [25] uses a similar idea
to give ``inner models'' of set theories.
.)f
that if a
true interpretation of certain axioms can be established in such a way that
a particular predicate letter P is re-interpreted via a stronger formula Z
(i.e., one for which Z\(->P is provable), then Z is
indeed a possible reading for P, i.,e., P\(->Z (and hence P\o'\(->\(<-'Z)
is consistent with those axioms. 
He further observed that this establishing might be possible
within the
very theory itself having those axioms. Thus McCarthy has discovered
a technique for determining, at least in some cases, when a particular wff
is \fInot\fR a logical consequence of others.\**
.(f
\**In effect, circumscription involves a relative consistency proof, that
identity of P and Z is consistent with (and relative to) A[P].
.)f
This is a very striking
result, for in general the logical consequences of a set of wffs are at
best only semi-decidable; thus there is hope now that in many cases of
interest to commonsense reasoning, a computationally viable mechanism may be
available to determine when a wff is \fInot\fR one of those among what a particular
agent knows (can conclude). This is of importance because of the central
role that ``what I don't know'' plays in non-monotonic reasoning in general.
.pp
Now, McCarthy and others have studied this from the point of view of
asserting P\(->Z once Z is established as an
alternative possible interpretation of P.
The typical conclusion then has the form: from \(noZx conclude \(noPx
(since P \(-> Z). 
This has seemed appropriate to the main
goal of modeling minimizing assumptions as in default reasoning.
But formulations to date have made the passage from the possibility
of Z to P\(->Z (and hence to \(noPx given \(noZx) in one fell swoop, rather than first recording
the possibility as a result in its own right and then with a further
axiom (when desired) basing the minimizing of P via P\(->Z
on the former. 
However, there are at least three advantages to separating the possibility (or
relative consistency) of \(noPx given \(noZx from the \fIconclusion\fR
that in fact \(noPx holds (given \(noZx):
.sp
.ls 1
1. It is not always the case that one wishes to minimize all possible
interpretations, yet one might still want to know of their viability.
Indeed, McCarthy early on [12] characterized circumscription as ``a rule
of conjecture,'' which suggests something tentative like possibility
or viability rather
than a definitive conclusion.
.sp
2. This is directly related to negative
introspection: how is it determined that a given wff is \fInot\fR among
the reasoner's conclusions? While this is in general undecidable,
many cases of it are of critical importance in commonsense reasoning.
An approach to possibility then might afford a computational means to
decide (many such) cases. This is the main issue addressed in this paper.
.sp
3. The semantics of possibility are simpler to study, and in particular
the conclusion of possibility is \fIsound\fR: if there is a true interpretation
Z of P for which, say, Zb is false, then Pb \fIcannot\fR be provable (unless
the original theory is inconsistent).
.ls 2
.pp
These (and especially 2.) will be taken up at greater length below.  In the present section we aim
mainly at discussing some of the choices available for formal mechanisms
involved in such an undertaking.  What we wish to do, then, is formalize the
idea that if there is a true interpretation of a set of axioms, in which P
is re-interpreted as Z, then from \(noZx we conclude only \(noConcluded(Px).
Clearly this is different from concluding that \(noPx.
An overview of the theme we are pursuing can be indicated in the following
diagram, where \fIC\fR stands for some mechanism that sets up
conditions under which it may be desirable to conclude non-monotonically
that \(noPx.
.ls 1
.in +10
.ti +5
default
.br
\fIC\fR ----------------------------------\(-> \(noPx
.br
                                            
                                          
    oracle                       jump
                                      
                                    
              \(noConcluded(Px)
.in -10
.sp
.ls 2
.pp
Here \fIC\fR could be a portion of McCarthy's circumscription schema (as
used below), or appropriate aspects of Reiter's [23] or McDermott & 
Doyle's [14]  forms 
of non-monotonic reasoning. The point is that the conclusion of the default
has been broken into two steps, first recognizing explicitly the fact that
the default conclusion is not prevented by anything known, and then the
actual passage to the default. In Perlis [19] these steps are 
called the `oracle' and the `jump' respectively. However, here we will be
exploring the extent to which a variation on circumscription can actually
render the oracle computationally feasible.\**
.(f
\**The name `oracle' was chosen
before to indicate an intractable (even undecidable) problem -- namely,
that of determining non-provability -- so that now
it may be inappropriate.
.)f
.pp
Note that a fully ``internal'' solution is impossible within a fixed theory
T. That is, Go\*:del [4] and Lo\*:b [11] showed that if T is consistent, then under
very general conditions |$-/ - sub T ~\(noThm sub T (\(*a)$\fR for \fIany\fR 
wff \(*a. Thus we must augment T, in order to get conclusions such as\fR
$\(noThm sub T (\(*a)$\fR. Even here we are stymied by the fact that
the wffs \(*a for which |$-/ - sub T ~\(*a$ form a semi-undecidable set in general.
However, we may succeed in getting many particular cases, and this is
what circumscription will allow us to achieve.\**
.(f
\**Actually, because we will not use Thm but rather another predicate, the
Go\*:del-Lo\*:b result might not apply; see Perlis [21] for a discussion of
these issues in a general setting.
.)f
.sp
\fBII. An Introspective Treatment\fR
.pp
We begin by recalling one standard form of circumscription, the so-called
predicate\**
.(f
\**Below we will switch to \fIformula\fR circumscription; our
comments here apply equally to both versions.
.)f
circumscription schema (McCarthy [12]) where Z is an arbitrary wff:
.ce
(1)			A[Z] & (\*(qax)(Zx \(-> Px) .\(->.  (\*(qax)(Px \(-> Zx) 	
Here A[P] is given
as (a conjoined set of) axioms, and A[Z] is this conjunction rewritten by substituting Z
for P.  It is natural to think of Z as a candidate interpretation for (the
underdetermined) P.  For instance, suppose A[P] is the conjunction
of Pb and (\*(qax)(Qx \(-> Px); this might formalize the idea that b is
winged, and that flyers are winged.  However, A[P] really says very little
as to what winged things (P-things) are:  all we know is that b is one, and
flyers (Q-things) are winged.  This leaves open what the extent of winged
things is.  Possibly b is the only such, possibly not.  The predicate
circumscription schema above has as consequence that, after all, the class
of winged things is the smallest class Z satisfying A[Z], i.e., the
union of the class of flyers and the object b.  For
we need only choose Z to be the formula Qx v x=b. Then A[Z]  and Zx \(-> Px
follow from A[P], so the schema yields (\*(qax)(Px \(-> Zx),
i.e., (\*(qax)(Px \(->. Qx v x=b).
.pp
Now suppose we wish to know that Qx v x=b is a \fIpossible\fR interpretation
of P, i.e., that winged things \fImay be\fR precisely b and the flyers, but we are
not prepared to conclude, yet, that this is \fItrue.\fR Then we must avoid
the final part of the schema, namely (\*(qax)(Px \(-> Zx). What can we put
in its place? We presumably want something like Possible(\*(qax)(Px \(-> Zx).
However, there is a simpler and more useful formulation, namely
we first rewrite the consequent in contrapositive form and rearrange
to emphasize the negative conclusion:
.ce
A[Z] & (\*(qax)(Zx \(-> Px) & \(noZy  .\(->.  \(noPy
and then instead of the boldness of \(noPx we use  \(noConcluded(Px),
i.e., rather than assert that Px is \fIfalse,\fR we simply record
that it is not concluded that Px, where for brevity we employ the symbol K
rather than Concluded:
.ce
(2)			A[Z] & (\*(qax)(Zx \(-> Px) & \(noZy  .\(->.  \(noK(Py)		
Thus this amounts to a kind of meta-conclusion about the reasoner's
own conclusions: the reasoner is (to be) endowed with the ability to
introspect that it has not been able to draw certain conclusions.
Determining the truth of A[Z] can be seen then as a
discovery that we have built a viable theory or possible world.
That is, A[Z] can be regarded as asserting
that Z is a possible interpretation of P, or represents a possible world
with respect to the knowledge A[P], since it says that Z satisfies
all that we know about P anyway (namely, A[P]); then if y does not
satisfy Z (P's possible interpretation), Py cannot have been known.
The advantage to using \(noK(Py) -- or Possible(\(noPy) -- instead of Possible(\*(qax)(Px \(->
Zx) will emerge below. 
.pp
There is another question of interpretation that arises. Namely,
what is the role of the subformula
.br
(\*(qax)(Zx \(-> Px) here? In circumscription
proper, it is essential in dealing with disjunctive axioms (see McCarthy
[12]).\**
.(f
\**If P is viewed as \fIunusual\fR this says P's substitute Z introduces no new
unusual entities.
.)f
But if we seek simply to determine ignorance rather than to minimize,
its appropriateness is unclear. There are two viewpoints that naturally
arise: we can dispense with this subformula altogether, seeking the most
general
range of possible interpretations of P, or we can retain it with an eye
to possible future use in minimizations or defaults. 
.pp
This is worth exploring a bit more. Suppose that our axioms A[P]
consist of Pa v Pb and a\(!=b. Then a reasonable ignorance-tester should show that
neither Pa nor Pb is concluded from A[P]: \(noKPa & \(noKPb.
On the other hand, if we
accept as a default (or P-minimizing) rule that \(noK(Px) \(-> \(noPx, we immediately
run into inconsistency (which is what prompted McCarthy's use of the
additional subformula in question). Now, this does not mean that it
is a mistake to state that ``neither Pa nor Pb is concluded from A[P].''
It simply means that such observations do not lend themselves directly
to default reasoning. Hence if our interest is primarily in determining
what is (not) concluded, it may be appropriate to dispense with the
subformula; and for later use in defaults it may be appropriate to retain
it and thereby find fewer candidate wffs determined to be unconcluded.
Of course, we could just as well undertake \fIboth\fR approaches at once,
employing different notations: GenK and MinK -- general concludability
and minimizing concludability. It is the latter (MinK, which is (2) above) that bears direct
relation to standard circumscriptive formalisms and default reasoning,
namely we have the obvious result that
.ce
(3)			(2) + \(noK(Py) \(-> \(noPy   entails   (1)			
In what follows, except for one explicit application to default reasoning,
we will avoid the added complexity of juggling two versions, and employ a single
version (GenK, (4) below) without the subformula, for conciseness of exposition. However,
much of what we say will apply equally to the alternate version.
Thus the version we will study has the form
.ce
(4)			A[Z] & \(noZy  .\(->.  \(noK(Py)				
whose purpose is not to elucidate circumscription so much as to borrow
a portion of the underlying idea of circumscription in order to address
the negative introspection problem.\**
.(f
\**Vladimir Lifschitz has suggested an elegant generalization of (4), along the lines of
K(Px) \o'\(->\(<-' (\*(qap)(A(p) \(-> px), where p is a second-order
predicate variable. This
brings out the idea of possible worlds more forcefully and
provides positive introspection as well.
.)f
.pp
Before proceeding into details, we mention that Konolige [6] and Levesque [7] 
have undertaken similar tasks. Konolige studies the problem of drawing
conclusions on the basis of knowing what an agent does not know.
He uses a modal \fIpropositional\fR logic for this purpose, and thus can retain
decidability; this represents a rather limited language, however.
Levesque pursues the same goal via a special modal
semantics that does not have (in its quantificational version) a corresponding
semidecidable proof-theoretic 
component; this serves his purpose since his logic is not intended
as an effective calculus for a reasoning agent. Autocircumscription, on the
other hand, is so intended, and it is important then that it be
semidecidable (and it is) even though a
quantificational language is used.
.sp
\fBIII. Technical Details\fR
.pp
There is one obvious aspect in which a complication arises:  the syntax of
the underlying first-order language must include names for wffs, so that
they can appear as terms in formulas.  That is, we must reify wffs as
first-order objects.  This is not new, however; ways to do this are given
in
(Feferman [3] and Perlis [18]).  Feferman meets the technical requirement
as follows: for each
wff $w$ in the language, there is a designated term $t sub w$ whose free variables
are those of $w$. Thus $t sub w$ is a function symbol with variables (or constant symbol
if $w$ has no free variables).\**
.(f
\**This device is sometimes called `quasi-quoting.'
.)f
Call a language `reified' if it is so endowed
with terms. Note that since $t sub w$ is itself in the language, it
gives rise to other terms naming wffs in which $t sub w$ appears. Since
context makes clear the usage, we will simply use `w' for $t sub w$,
or even just $w$ itself; however, $t sub w$ itself, being a term, does
not contain the wff w, nor any predicate letters at all.
.pp
Thus we may employ a predicate expression
K(`w') where `w' is the name of a wff, to mean that
the wff (named) `w' is concluded by our reasoning agent g. The predicate
symbol K can just as well be read as ``g knows (or believes)''
its argument, or better yet, ``I know'' the argument. If w has free
variables, then the wff K($t sub w$\fR) (also written as K(`w') above and
as Kw) does too; this allows for quantifying into what otherwise might
appear to be opaque contexts.
.pp
Suppose then that L is a reified first-order language, with predicate symbol
K. Then we can present a
revised schema, in a form we call \fIautocircumscription\fR (for it is
designed to isolate the feature of determining what is (not) known to the
agent \fIitself\fR, rather than what is (not) true in the outer world).
For greater generality we turn to \fIformula\fR circumscription (McCarthy [13]),
written in a first-order version. Let A[P] be a finite conjunction
of wffs of L, where P is a tuple of predicate letters
P\*\*<0\*>,...,P\*<n\*> appearing in A[P]. Let
Z be the tuple of wffs Z\*\*<0\*>,...,Z\*<n\*>, and
W[P,x] any wff to be minimized (and in which the predicate letters P and variable(s) x may 
figure). Then one version of formula circumscription is:
.ce
A[Z] & (\*(qax)(W[Z,x]\(->W[P,x]) & \(noW[Z,y]  .\(->.  \(noW[P,y]
The idea is that the predicate letters P\*\*<0\*>,...,P\*<n\*> in the 
original axiom A[P\*\*<0\*>,...,P\*<n\*>], are open to
interpretations Z\*\*<0\*>,...,Z\*<n\*>, respectively (which are to be
chosen suitably, and where care is taken to avoid clash of
variables -- see Mott [16]). Then if W[P] is ``minimal'' with respect to
A[P], and fails at y under the Z-interpretation, W must also
fail at y for the original P.\**
.(f
\**Thus W[P,x] is a special wff \fIdesignated\fR for minimization.
.)f
.pp
The corresponding \fIautocircumscription\fR schema for an
axiom set A = A[P\*\*<0\*>,...,P\*<n\*>] is:
.ce
AUTO:			A[Z] & \(noW[Z,y]  .\(->.  \(noK W[P,y]				\ 
The formula of which ignorance is being tested is represented by
W[P,y].
The idea, as before, is that if there
is an interpretation Z\*\*<0\*>,...,Z\*<n\*> of the predicates
P\*\*<0\*>,...,P\*<n\*> such that A[Z\*\*<0\*>,...,Z\*<n\*>]
holds, then this is a possible interpretation, so that we must have
been ignorant of any fact about W[P,y] that happens to fail for W[Z,y].
.pp
One feature of autocircumscription is that, unlike minimizing versions of
circumscription, no special license is needed in choosing the wff W.  In
fact, \fIall\fR wffs can be ignorance-tested at once with impunity.  Thus we
regard autocircumscription as a schema not only for Z but also for W.\**
.(f
\**Certain versions of circumscription, such as in [13] and [20],
probably could facilitate corresponding versions of autocircumscription in a
single (higher-order or set-theoretic) formula.
.)f
For
the same reason, in the schema we can assume that
P\*\*<0\*>,...,P\*<n\*> are \fIall\fR the predicate letters in
A[P].  Thus we do not bother to write A[P] anymore but just A.
We introduce the notation AUTO[A] to stand for the above schema (over \fIall
W's\fR) together with A itself, making AUTO[A] an extension of A:
AUTO[A]  =  A + AUTO.
.pp
Now, what is preferable about this version over the one with
Possible(\*(qax)(W[P,x] \(-> W[Z,x])? Well, the latter would require us to write
axioms for Possible in a way that would
to break apart (\*(qax)(W[P,x] \(-> W[Z,x]) into subformulas so that knowing, say
\(noW[Z,c], would allow a conclusion about the possibility of \(noW[P,c]. Schema AUTO
avoids this by placing K directly where desired.
.pp
Another idea is to minimize the predicate K itself with
ordinary circumscription, rather than go to the trouble of inventing a new
version. However, to make it useful, axioms relating
K to the actual provability conditions of the underlying theory would be necessary, and this is not
at all easy.\**
.(f
\**See Perlis [21]. Nevertheless, provability provides a key to a
sound \fIsemantics\fR for autocircumscription; this will be taken up
in the theorems below. Also, Lin [10] has carried out such a K-minimization
in the case of a propositional modal formulation of circumscription.
.)f
The present approach, on the other hand, requires no particular
axiomatization of K, for it serves via AUTO simply to record when a wff is
\fInot\fR a theorem of A. If A does have theorems of the form K\(*a,
this is not necessarily a problem, as long as it respects the intended
meaning of K, as we now define.
.in +3
.sp
\fBDefinition:\fR A theory T is \fIautoconsistent\fR\**
.(f
\**Note the similarity to the notion of a stable
autoepistemic theory (see Moore [15] and Stalnaker [26]); however, our notion
is weaker, as it must be by Theorem 7.7 in Perlis [21] showing in effect 
that suitably reified (substitutive) stable theories are inconsistent.
That is, fully (positive \fIand\fR negative) introspective consistent theories
with self-reference do not exist.
.)f
(for the predicate letter K) if the language of T is reified and has the 
predicate letter K and for every wff \(*a
.in +5
1. T |$-$\fR K\(*a  implies  T |$-$\fR \(*a  and
.br
2. T |$-$\fR \(noK\(*a  implies  T |\o'/$-$'\fR \(*a
.in -5
.sp
\fBDefinition:\fR A theory B \fIautoextends\fR theory A -- or is an 
autoextension of A, or is autoextensional over A --
for the predicate letter K, if B is an extension of A, the language of B is reified and has the 
predicate letter K, and for every wff \(*a
.in +5
1. B |$-$\fR K\(*a  implies  A |$-$\fR \(*a  and
.br
2. B |$-$\fR \(noK\(*a  implies  A |\o'/$-$'\fR \(*a
.in -5
.in -3
.pp
Thus a theory is autoconsistent iff it is an autoextension of itself; and
theorems of an autoextension B of a theory A do not violate the intended
meaning of Kx, namely that x is a theorem (of the original theory A).  If A
is autoconsistent, then A itself has explicit information as to its own
proof theory; sometimes this is too much to expect (see [4,11,21] and the
discussion after Theorem 3 below).
.sp
.in +3
\fBLemma:\fR If T is autoconsistent, then T is consistent. If T is consistent
and S autoextends T then S is consistent.

\fBProof:\fR Suppose T is autoconsistent. Let \(*a be any wff. Then if \(noK\(*a
is not a theorem, T is consistent (since \fIall\fR wffs are theorems of
inconsistent theories). Yet if \(noK\(*a \fIis\fR a theorem, then 
autoconsistency requires that \(*a not be, so again T is consistent.

Now suppose T is consistent and S is an autoextension of T.  If S were
inconsistent then, for any wff \(*a of T, both K\(*a and K\(no\(*a would be
theorems of S, hence both \(*a and \(no\(*a would be theorems of T,
contradicting T's consistency.
.sp
\fBTheorem 1:\fR If T is consistent and does not involve the symbol K
in its proper axioms, then AUTO[T] is consistent. 
.sp
\fBProof\fR (suggested by a referee): Interpret K as ``true'' in any
model of T; this will automatically satisfy all instances of the
autocircumscription schema.
.in -3
.pp
However, we can require more of AUTO[T], namely that it autoextend T,
for this is after all the intension behind autocircumscription. We also
may want T to have axioms involving K. We then have the following result.
.sp
.in +3
\fBTheorem 2:\fR If the only proper axioms of T = T[P\*\*<0\*>,...,P\*<n\*>] 
that involve K are literals, and if T is autoconsistent, then AUTO[T]
is consistent and even autoextensional over T.
.sp
\fBProof:\fR
Call a wff \fIK-free\fR if it does not involve the predicate symbol K.
Since T is autoconsistent then by the Lemma, T is consistent.
Let M be a model of the K-free axioms of T. Then
interpret `K(\(*a)' in M as
T\ |$-$\fR\ \(*a, for each wff \(*a in the language of T. That is, Kx is
interpreted over D=Domain(M) as meaning that x is the name of a wff
that is provable in T. This makes M a model of
(all of) T, since the literal axioms involving K will be satisfied from
the autoconsistency: if K\(*a is an axiom of T then so is \(*a and thus
(by the interpretation of K in M) K\(*a is true in M. And if \(noK\(*a
is a theorem of T, then (any instantiation over D of) K\*(a is false
in M, for if it were true then (that instantiation of) \(*a would be
a theorem of T which in turn (by autoconsistency) would bar (the
instantiation of) \(noK\(*a from theoremhood.

But M is also a model
of AUTO[T]. For AUTO[T] consists of T plus conclusions of the form \(noK
W[P,y] given antecedents T[Z] & \(noW[Z,y] for any vector of wffs Z.
We have to show that if the antecedents hold in M then so does the
conclusion \(noK W[P,y], i.e., W[P,y] is not a theorem of T for any
y in D. But if (some instantiation over D of)
W[P,y] were a theorem of T=T[P], then (the corresponding instantiation of)
W[Z,y] would be a consequence of T[Z], and so W[P,y] would hold in M.
This contradicts the antecedent \(noW[Z,y],
which we are assuming to hold in M. This shows that (an instantiation of) 
W[P,y] cannot
be a theorem of T after all. Thus (each instantiation of) K W[P,y] is 
false in M, 
so \(noK W[P,y] is true in M. This shows that M is a model
for AUTO[T], and therefore AUTO[T] is consistent. 

Now AUTO[T] also autoextends T, since if AUTO[T] |$-$ K\(*a for
some wff \(*a of T, then K\(*a is true in M, so T |$-$ \(*a. And
if AUTO[T] |$-$ \(noK\(*a, then again \(noK\(*a is true
in M so T |\o'/$-$' \(*a.
.in -3
.pp
Note that the proof does not make any use of information as to \fIwhich\fR
wff W is the one being ignorance-tested. This corroborates our earlier claim
that we may as well consider AUTO[T] to
\fIsimultaneously\fR be applied to \fIall\fR wffs W.
.sp
.in +3
\fBCorollary:\fR If T is consistent and does not involve K in its
proper axioms, then AUTO[T] is also consistent and autoextends T.
.in -3
.pp
These results provide a sharp formal distinction between autocircumscription
and the standard (minimizing) varieties. For as has been shown by 
Davis [1], Etherington et al [2],
and Mott [16], peculiarities and even inconsistencies can occur
when a circumscription schema (or second-order axiom) is adjoined to
certain theories. Indeed, these authors have been at pains to isolate special cases in which
consistency is preserved. But for autocircumscription, consistency is
preserved, barring the use of K for defaults.
If we try to recapture
actual minimizations by adjoining default rules using `K,' then
we again have the full force of minimizing circumscription and so once
more the specter of inconsistency can arise.
.pp
But even here we have a positive result. We recall a definition from
[21]: a \fIMoorean autoepistemic\fR (or MAE) wff is one of the form \(*a \(-> K\(*a.
The prototypical example [15] is the sentence ``If I had a brother I would know
it.'' These can be regarded as defaults (true instances of having a brother
\fItypically\fR are
known), or, as Moore prefers, as autoepistemic beliefs (true instances of my having a 
brother \fIare\fR known to me). The distinction between these, important
for some purposes, is not critical here, so we refer to MAE wffs as defaults.
.in +3

\fBTheorem 3:\fR If T is autoconsistent and the only proper axioms of T involving K
are literals and at most one MAE wff $\(*a sub 0$\fR\(->K$\(*a sub 0$\fR where
$\(*a sub 0$\fR is a K-free sentence, then AUTO[T] is consistent.

\fBProof\fR: Construct M as in the proof of Theorem 2, such 
that if T |\o'/$-$'\fR $\(*a sub 0$\fR then M |\o'=/' $\(*a sub 0$\fR; this is easy since $\(*a sub 0$\fR is K-free.
Now M will satisfy the MAE wff above since either
T\ |$-$\fR $\(*a sub 0$\fR and so K$\(*a sub 0$\fR is true in M, or T |\o'/$-$'\fR $\(*a sub 0$\fR and so by construction
M |\o'$=$/'\fR $\(*a sub 0$\fR; in either case the MAE wff is true in M. Thus M is a model
for T and then also for AUTO[T] as in the proof of Theorem 2.
So AUTO[T] is consistent.
.in -3
.pp
Unfortunately, we cannot guarantee AUTO[T] to be an \fIauto\fRextension T in the above
theorem. For instance, if neither $\(*a sub 0$\fR nor \(no$\(*a sub 0$\fR is a theorem of T, then we
may find both \(noK$\(*a sub 0$\fR and \(noK\(no$\(*a sub 0$\fR as theorems of AUTO[T]. But
the MAE wff and \(noK$\(*a sub 0$\fR produce \(no$\(*a sub 0$\fR, which together with
\(noK\(no$\(*a sub 0$\fR violates autoextensionality (and of course also
autoconsistency). We see this, however, not as a
defect of autocircumscription, but rather as a general feature of default
(or non-monotonic) reasoning lying outside of ignorance-testing per se.\**
.(f
\** This issue is the point of another paper,
in progress, on the essentially process-oriented nature of default reasoning.
.)f
.pp
It is also easy to see that the restriction to \fIone\fR MAE default is
necessary (in general). For if T has the axioms PvQ, P\(->KP,
Q\(->KQ, then AUTO[T] yields \(noKP and \(noKQ, which in turn
yield \(noP and \(noQ, contradicting PvQ. While this in no
way is a comment against \(noKP and \(noKQ (they are literally
true about T) it is a comment against the free use of defaults.\**
.(f
\**See Reiter & Criscuolo [24] and Hanks & McDermott [5] for more on 
interacting defaults.
It would be nice not to have to make this restriction;
however, in [19] and [21] evidence is given suggesting that \fIany\fR formalism
for default reasoning that formally represents too much of its own behavior
will face problems of inconsistency.
.)f
.sp
\fBIV. Applications\fR
.pp
\fBA.\fR Suppose I have the belief that I am more knowledgeable than Bill
about LISP, and in particular that if I don't know some proposition 
about LISP then neither does he. Now, this will allow me to infer
\(noKnow(Bill,y)
\fIif\fR I can first infer \(noKnow(me,y). This
is where a technical ignorance-prover will be of use. Taking
\fIKnow(me,x)\fR to be the first-order predicate \fIK(x)\fR, 
the autocircumscription schema will facilitate
establishing that I do not know (certain cases of) y, so that useful
conclusions (Bill's ignorance of y) can follow.
.pp
Note that this example
is \fInot\fR contingent on, or even significantly related to, the
separate issue of whether the proposition y happens to be \fItrue\fR.
Nonetheless,
interesting conclusions are derivable, namely that it is indeed unknown
to me, and also unknown to Bill. Also note that this allows us at the same time
to recognize two competing theories about the world: that y is true, and that
y is false. While clearly we know y v \(noy already (a tautology), we do
not know, without the negative introspection that autocircumscription affords
us, that either of these is a possibility, let alone both. Further reasoning
then might lead us to accept or reject one or the other of these theories.
.pp
\fBB.\fR As our second example, we offer one raised by McCarthy [personal communication, 1984]:
How can an agent decide that, on the basis of all it knows, the question as
to whether
Ronald Reagan is (currently) standing or seated is indeterminate?
Here the K predicate together with the autocircumscription schema,
solves this problem. For instance, let an agent have the following axioms A[Seated,Standing]:
.ce
{Seated(Bill), \(noSeated(Sue), Seated(x) \o'\(->\(<-' \(noStanding(x), Ronald Reagan \(!= Bill, Ronald Reagan \(!= Sue}
Then letting Z\*\*<0\*>(x) be x=Bill, and Z\*<1\*>(x) be x\(!=Bill,
we find A[Z\*\*<0\*>,Z\*<1\*>].
But then taking $P sub 0$\fR to be W[$P sub 0 ,P sub 1$\fR]
AUTO[A] will give us \(no$Z sub 0$\fR(y) \(-> \(noK(`Seated(y)'),
from which we get 
\(noK(`Seated(Ronald Reagan)').
Similarly we can show \(noK(`Standing(Ronald Reagan)').
Thus both Seated(Ronald Reagan) \fIand\fR Standing(Ronald Reagan) have
been shown not to be provable from the axiom set A.
.pp
\fBC.\fR Our final example is Moore's Brother Problem, alluded to earlier.
Let us suppose that we know Fc (Carl, c, is a friend).
We postulate the MAE wff Bc \(-> KBc (if Carl is my brother, I will know it).
The aim is to be able to derive \(noKBc (I do not know Carl to be my
brother) and then \(noBc (Carl is not my brother); and indeed,
more generally, \(noKBx. Thus our theory T[B,F,K] has the axioms
Bc \(-> KBc
and
Fc.
.pp
Note that by Theorem 3, AUTO[T] will be consistent: T is consistent
and involves K only once, in a single MAE wff applied to the sentence Bc.
We show that AUTO[T] |$-$\fR \(noKBx. We simply interpret Bx as always
false; that is, let $Z sub 0$\fRx be x\(!=x. Then T[$\fRZ sub 0$\fR,F,K] is readily provable, and so is
\(no$\fRZ sub 0$\fRx; we get immediately \(noKBx. Consequently from the MAE wff we find \(noBc, and
we have established that Carl is not the agent's brother! 
.pp
It would be more natural, not to mention convenient, to postulate the
more general MAE wff Bx \(-> KBx; however Theorem 3 then does not apply
since Bx has a free variable and so is not a sentence. In fact, in this case the above example will
fail with disjunctive information such as Bc v Bd. However, the failure will
occur not at the stage of negative introspection or oracle (\(noKBc & \(noKBd) but at
the stage of default conclusion or jump (\(noBc & \(noBd). Of course, a case
like this flies in the face of the original default or autoepistemic belief.
.sp
\fBV. Conclusions\fR
.pp
Certain more specialized forms of reasoning such
as defaults and auto-epistemic conclusions may be viewed as
embellishments of theory-building (proving possibility) which in turn
lends itself
to formalization via autocircumscription.
This will not work in
every case, due to the undecidability of consistency. But perhaps most
cases of interest to commonsense reasoning can be so handled.
.bp
.ls1
\fBAcknowledgement\fR
.br
I wish to thank Halina Przymusinska, Vladimir Lifschitz, Brian Haugh,
Kave Eshghi, Martin Davis and anonymous referees for
very eye-opening and constructive criticism.
This research has been supported in part by the U.S. Army Research 
Office (DAAL03-88-K0087) and the Martin Marietta Corporation.

\fBReferences\fR
.np 
Davis,  M. [1980]  The mathematics of non-monotonic reasoning.
\fIArtificial Intelligence\fR \fI13\fR, 73-80.
.np 
Etherington, D, Mercer, R., and Reiter, R. [1985] On the adequacy of predicate
circumscription for closed-world reasoning. \fIComputational
Intelligence\fR \fI1\fR, 11-15.
.np
Feferman, S. [1984] Toward useful type-free theories. \fIJ. Symbolic
Logic, 49\fR, 75-111.
.np
Go\*:del, K. [1931] Uber formal unentscheidbare Satze der Principia Mathematica und 
verwandter Systeme I, \fIMonatsh. Math. Phys.,\fR 38, pp. 173-198.
.np 
Hanks, S. and McDermott, D. [1987] Nonmonotonic logic and temporal
projection. \fIArtificial Intelligence, 33\fR, 379-412.
.np
Konolige, K. [1982] Circumscriptive ignorance.  Proc.  AAAI-82, 
pp. 202-204.
.np
Levesque, H. [1987] All I know: an abridged report. Proceedings, AAAI-87,
pp. 426-431.
.np 
Lifschitz, V. [1986] On the satisfiability of circumscription. 
\fIArtificial Intelligence\fR \fI28\fR, 17-28.
.np 
Lifschitz, V. [1987] Circumscriptive theories: a logic-based framework
for knowledge representation (preliminary report). Proceedings,
AAAI-87, pp. 364-368.
.np
Lin, Fangzhen [1988] Circumscription in a modal logic, Proc. of
the 2nd Conference on Theoretical Aspects of Reasoning about
Knowledge (Moshe Vardi, ed.) pp. 113-127. Morgan-Kaufmann.
.np
Lo\*:b, M. [1955] Solution to a problem of Leon Henkin. \fIJournal of
Symbolic Logic,\fR 20, pp. 115-118.
.np
McCarthy, J. [1980] Circumscription--a form of non-monotonic
reasoning. \fIArtificial Intelligence\fR \fI13\fR, 27-39.
.np 
McCarthy, J. [1986] Applications of circumscription to formalizing
common-sense knowledge. \fIArtificial Intelligence\fR, \fI28\fR, 89-118.
.np 
McDermott, D. and Doyle, J. [1980] Non-Monotonic Logic I. \fIArtificial
Intelligence 13\fR, 41-72.
.np 
Moore, R. [1985] Semantical considerations on non-monotonic logic.
\fIArtificial Intelligence 25\fR, pp. 75-94.
.np
Mott, P. [1987] A theorem on the consistency of circumscription.
\fIArtificial Intelligence 31\fR, 87-98.
.np
Perlis, D. [1981] Language, computation, and reality, PhD Thesis,
Univ. of Rochester, Rochester NY.
.np 
Perlis, D. [1985] Languages with self reference I: foundations. 
\fIArtificial Intelligence 25\fR, 301-322.
.np 
Perlis, D. [1986] On the consistency of commonsense reasoning.
\fIComputational Intelligence\fR \fI2\fR, 180-190.
.np 
Perlis, D. [1987] Circumscribing with sets. \fIArtificial Intelligence
31\fR, 201-211.
.np 
Perlis, D. [1988] Languages with self reference II: knowledge, belief,
and modality. \fIArtificial Intelligence, 34\fR, 179-212.
.np 
Perlis, D., and Minker, J. [1986] Completeness results for circumscription.
\fIArtificial Intelligence\fR \fI28\fR 29-42
.np 
Reiter, R. [1980] A logic for default reasoning. \fIArtificial
Intelligence\fR \fI13\fR, 81-132.
.np
Reiter, R.  and Criscuolo, G.  [1981] On interacting defaults. 
Proceedings of the Seventh International Joint Conference on Artificial
Intelligence, pp 270-276.
.np
Shepherdson, J. [1951] Inner models for set theory I. \fIJ Symbolic Logic,
16,\fR 161-190.
.np
Stalnaker, R. [unpublished] A note on non-monotonic logic. Manuscript,
Philosophy Department, Cornell University.
